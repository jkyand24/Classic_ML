{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m model \u001b[39m=\u001b[39m SVC(C\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_features\u001b[39m.\u001b[39;49mnumpy(), train_labels\u001b[39m.\u001b[39;49mnumpy())\n\u001b[0;32m     46\u001b[0m acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(test_features\u001b[39m.\u001b[39mnumpy(), test_labels\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     48\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 251\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    252\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    319\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    321\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    323\u001b[0m (\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 333\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    334\u001b[0m     X,\n\u001b[0;32m    335\u001b[0m     y,\n\u001b[0;32m    336\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    337\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    338\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[0;32m    339\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    340\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    341\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    342\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    343\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    344\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    345\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    346\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    347\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    348\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    349\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    350\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    351\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False, num_workers=2)\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(inputs.shape[0], -1)\n",
    "    \n",
    "    train_features.append(inputs)\n",
    "    train_labels.append(labels)\n",
    "    \n",
    "train_features = torch.cat(train_features, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(inputs.shape[0], -1)\n",
    "    \n",
    "    test_features.append(inputs)\n",
    "    test_labels.append(labels)\n",
    "    \n",
    "test_features = torch.cat(test_features, dim=0)\n",
    "test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "#\n",
    "\n",
    "print(\"SVM model Train & Test\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = SVC(C=1.0, kernel='rbf', gamma=0.01)\n",
    "\n",
    "model.fit(train_features.numpy(), train_labels.numpy())\n",
    "\n",
    "acc = model.score(test_features.numpy(), test_labels.numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Accuarcy: {acc}\")\n",
    "\n",
    "spent_time = end_time - start_time\n",
    "\n",
    "print(f\"Training, Test time: {spent_time:.2f} seconds\")\n",
    "\n",
    "#\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images = test_images.view(test_images.shape[0], -1)\n",
    "\n",
    "test_preds = model.predict(test_images.numpy())\n",
    "\n",
    "#\n",
    "\n",
    "def plot_images(images, labels, preds):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(images[i].reshape((28, 28)), cmap='gray')\n",
    "        title = f\"Label: {labels[i]}\\nPredicted: {preds[i]}\"\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.subplots_adjust(top=0.5, bottom=0, hspace=0, wspace=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_images(test_images.numpy(), test_labels.numpy(), test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
